{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import cv2 \nimport numpy as np \nfrom keras.applications import VGG16 \nfrom keras.layers import Flatten, Dense, Input \nfrom keras.models import Model \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import classification_report \nimport os \n# Function to convert RGB image to grayscale \ndef rgb_to_gray(image): \nreturn cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n# Function to apply MSR image enhancement \ndef multi_scale_retinex(image, sigma_list): \nretinex = np.zeros_like(image, dtype=np.float32)  # Specify dtype=float32 explicitly \nepsilon = 1e-8  # Small constant to avoid division by zero \nfor sigma in sigma_list: \nlog_image = np.log(image.astype(np.float32) + epsilon) \nblurred_image = cv2.GaussianBlur(image, (0, 0), sigma).astype(np.float32) \nlog_blurred_image = np.log(blurred_image + epsilon) \nretinex += log_image - log_blurred_image \nretinex = retinex / len(sigma_list) \n# Ensure retinex array is in the range [0, 255] and of type uint8 \nretinex = np.clip(retinex, 0, 255).astype(np.uint8) \nreturn retinex \n# Function to perform weighted average fusion of images \ndef weighted_average_fusion(image1, image2, alpha=0.5): \nreturn cv2.addWeighted(image1, alpha, image2, 1-alpha, 0) \n# Function to extract SIFT features \ndef extract_sift_features(image): \nsift = cv2.SIFT_create() \ngray_image = rgb_to_gray(image) \nkeypoints, descriptors = sift.detectAndCompute(gray_image, None) \nreturn descriptors \n# Load VGG16 model without classification layer \nvgg_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3))) \nfor layer in vgg_model.layers: \nlayer.trainable = False \n# Add classification layers on top of VGG16 \nx = Flatten()(vgg_model.output) \nx = Dense(2048, activation='relu')(x) \nx = Dense(2, activation='softmax')(x) \nvgg_model = Model(inputs=vgg_model.input, outputs=x) \n# Compile the model \nvgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n# Load CelebA-Spoof dataset (example) \ndataset_path = r\"./spandy/train\" \nreal_images_folder = os.path.join(dataset_path, \"REAL\") \nspoof_images_folder = os.path.join(dataset_path, \"FAKE\") \n# Assuming you have spoof dataset with image paths and labels \nimage_paths = [] \nlabels = [] \n# Load real images \nfor filename in os.listdir(real_images_folder): \nif filename.endswith(\".jpg\"): \nimage_paths.append(os.path.join(real_images_folder, filename)) \nlabels.append(0)  # Label 0 for real faces \n# Load spoof images \nfor filename in os.listdir(spoof_images_folder): \n    if filename.endswith(\".jpg\"): \n        image_paths.append(os.path.join(spoof_images_folder, filename)) \n        labels.append(1)  # Label 1 for spoof faces \n# Read images, apply preprocessing, and create dataset \nX = [] \ny = [] \nfor path, label in zip(image_paths, labels): \n    # Read image \n    image = cv2.imread(path) \n    # Apply MSR enhancement \n    enhanced_image = multi_scale_retinex(image, [15, 80, 250]) \n    # Resize images to fit VGG16 input size \n    image = cv2.resize(image, (224, 224)) \n    enhanced_image = cv2.resize(enhanced_image, (224, 224)) \n    # Perform weighted average fusion \n    fused_image = weighted_average_fusion(image, enhanced_image) \n    # Extract SIFT features \n    sift_features = extract_sift_features(fused_image) \n    # Append to dataset (concatenate features if needed) \n    if sift_features is not None and surf_features is not None: \n        features = np.concatenate((sift_features.flatten())) \n    elif sift_features is not None: \n        features = sift_features.flatten() \n    else: \n        features = np.array([]) \n    X.append(features) \n    y.append(label) \nX = np.array(X) \ny = np.array(y) \n# Ensure the dimensions of X are correct \nif X.ndim == 1: \nX = np.expand_dims(X, axis=0) \nprint(f\"Feature dataset shape: {X.shape}\") \nprint(f\"Labels shape: {y.shape}\") ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}